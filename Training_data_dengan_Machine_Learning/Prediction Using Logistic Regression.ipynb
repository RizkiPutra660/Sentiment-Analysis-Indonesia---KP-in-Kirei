{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'text'], dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('Tweets Indonesis.csv')\n",
    "data['text'] = data['text'].apply(str)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows per label:\n",
      " 1    11356\n",
      " 0     8315\n",
      "-1     7609\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "print(\"Number of rows per label:\")\n",
    "print(data['label'].value_counts())\n",
    "\n",
    "# Plotting the sentiment distribution\n",
    "plt.figure()\n",
    "pd.value_counts(data['label']).plot.bar(title=\"Sentiment distribution in data\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"No. of rows in data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After segregating and taking equal number of rows for each sentiment:\n",
      "-1    7500\n",
      " 1    7500\n",
      " 0    7500\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>suka banget cleanser cocok udah banget gonta g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>produk klaim makeup removal gak guna makeup re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>thanks god for this product produk udah cocok ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>another favorite product from cetaphil neng ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>kaget cleanser busa biasa suka cleanser gentle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>so far cocok cetaphil purchase kali botol paka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>my hg cleanser kulit yg oily kering arah dehid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>setia cethapil clenaser wajah produk wajah ber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>really really love this cleanser kulit wajah s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>cetaphil bikin kulit sehat bgt gatel kering be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  suka banget cleanser cocok udah banget gonta g...\n",
       "1      1  produk klaim makeup removal gak guna makeup re...\n",
       "2      1  thanks god for this product produk udah cocok ...\n",
       "3      1  another favorite product from cetaphil neng ba...\n",
       "4      1  kaget cleanser busa biasa suka cleanser gentle...\n",
       "5      1  so far cocok cetaphil purchase kali botol paka...\n",
       "6      1  my hg cleanser kulit yg oily kering arah dehid...\n",
       "7      1  setia cethapil clenaser wajah produk wajah ber...\n",
       "8      1  really really love this cleanser kulit wajah s...\n",
       "9      1  cetaphil bikin kulit sehat bgt gatel kering be..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data(top_n = 5000):\n",
    "    data_positive = data[data['label'] == 1].head(top_n)\n",
    "    data_negative = data[data['label'] == -1].head(top_n)\n",
    "    data_neutral= data[data['label'] == 0].head(top_n)\n",
    "    data_small = pd.concat([data_positive, data_negative, data_neutral])\n",
    "    return data_small\n",
    "\n",
    "# Function call to get the top 10000 from each sentiment\n",
    "data_small = get_data(top_n=7500)\n",
    "\n",
    "# After selecting top few samples of each sentiment\n",
    "print(\"After segregating and taking equal number of rows for each sentiment:\")\n",
    "print(data_small['label'].value_counts())\n",
    "data_small.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [suka, banget, cleanser, cocok, udah, banget, ...\n",
      "1    [produk, klaim, makeup, removal, gak, guna, ma...\n",
      "2    [thanks, god, for, this, product, produk, udah...\n",
      "3    [another, favorite, product, from, cetaphil, n...\n",
      "4    [kaget, cleanser, busa, biasa, suka, cleanser,...\n",
      "5    [so, far, cocok, cetaphil, purchase, kali, bot...\n",
      "6    [my, hg, cleanser, kulit, yg, oily, kering, ar...\n",
      "7    [setia, cethapil, clenaser, wajah, produk, waj...\n",
      "8    [really, really, love, this, cleanser, kulit, ...\n",
      "9    [cetaphil, bikin, kulit, sehat, bgt, gatel, ke...\n",
      "Name: tokenized_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "# Tokenize the text column to get the new column 'tokenized_text'\n",
    "data_small['tokenized_text'] = [simple_preprocess(line, deacc=True) for line in data_small['text']] \n",
    "print(data_small['tokenized_text'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for Train sentiments\n",
      " 1    5303\n",
      "-1    5235\n",
      " 0    5212\n",
      "Name: label, dtype: int64\n",
      "Value counts for Test sentiments\n",
      " 0    2288\n",
      "-1    2265\n",
      " 1    2197\n",
      "Name: label, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "   index                                               text  \\\n",
      "0   9499                                            gitu aq   \n",
      "1  21869                          laku banjir nampak bayang   \n",
      "2   8987               beneran nih ntar coba g o managernya   \n",
      "3   7899        banyak ugut terima panjang ugut tindak ugut   \n",
      "4  16132  bahas dosen hukum islam whoooooaaaaaa untung k...   \n",
      "\n",
      "                                      tokenized_text  \n",
      "0                                         [gitu, aq]  \n",
      "1                     [laku, banjir, nampak, bayang]  \n",
      "2             [beneran, nih, ntar, coba, managernya]  \n",
      "3  [banyak, ugut, terima, panjang, ugut, tindak, ...  \n",
      "4  [bahas, dosen, hukum, islam, whoooooaaaaaa, un...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Train Test Split Function\n",
    "def split_train_test(data_small, test_size=0.3, shuffle_state=True):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data_small[['text', 'tokenized_text']], \n",
    "                                                        data_small['label'], \n",
    "                                                        shuffle=shuffle_state,\n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=15)\n",
    "    print(\"Value counts for Train sentiments\")\n",
    "    print(Y_train.value_counts())\n",
    "    print(\"Value counts for Test sentiments\")\n",
    "    print(Y_test.value_counts())\n",
    "    print(type(X_train))\n",
    "    print(type(Y_train))\n",
    "    X_train = X_train.reset_index()\n",
    "    X_test = X_test.reset_index()\n",
    "    Y_train = Y_train.to_frame()\n",
    "    Y_train = Y_train.reset_index()\n",
    "    Y_test = Y_test.to_frame()\n",
    "    Y_test = Y_test.reset_index()\n",
    "    print(X_train.head())\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "# Call the train_test_split\n",
    "X_train, X_test, Y_train, Y_test = split_train_test(data_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available for running: \n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch\n",
    "# Use cuda if present\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device available for running: \")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary without padding\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "# Function to return the dictionary either with padding word or without padding\n",
    "def make_dict(data_small, padding=True):\n",
    "    if padding:\n",
    "        print(\"Dictionary with padded token added\")\n",
    "        review_dict = corpora.Dictionary([['pad']])\n",
    "        review_dict.add_documents(data_small['tokenized_text'])\n",
    "    else:\n",
    "        print(\"Dictionary without padding\")\n",
    "        review_dict = corpora.Dictionary(data_small['tokenized_text'])\n",
    "    return review_dict\n",
    "\n",
    "# Make the dictionary without padding for the basic models\n",
    "review_dict = make_dict(data_small, padding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(review_dict)\n",
    "NUM_LABELS = 3\n",
    "\n",
    "# Function to make bow vector to be used as input to network\n",
    "def make_bow_vector(review_dict, sentence):\n",
    "    vec = torch.zeros(VOCAB_SIZE, dtype=torch.float64, device=device)\n",
    "    for word in sentence:\n",
    "        vec[review_dict.token2id[word]] += 1\n",
    "    return vec.view(1, -1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target(label):\n",
    "    if label == -1:\n",
    "        return torch.tensor([0], dtype=torch.long, device=device)\n",
    "    elif label == 0:\n",
    "        return torch.tensor([1], dtype=torch.long, device=device)\n",
    "    else:\n",
    "        return torch.tensor([2], dtype=torch.long, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6122, -1.0176, -1.4748,  0.3432,  0.4568])\n",
      "\n",
      "Probabilities : \n",
      "tensor([0.1316, 0.0877, 0.0555, 0.3420, 0.3832])\n",
      "tensor(1.0000)\n",
      "\n",
      "Log probabilities\n",
      "tensor([-2.0283, -2.4336, -2.8909, -1.0729, -0.9593])\n"
     ]
    }
   ],
   "source": [
    "data = torch.randn(5)\n",
    "print(data)\n",
    "print(\"\\nProbabilities : \")\n",
    "print(F.softmax(data, dim=0))\n",
    "print(F.softmax(data, dim=0).sum())  # Sums to 1 because it is a distribution!\n",
    "print(\"\\nLog probabilities\")\n",
    "print(F.log_softmax(data, dim=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining neural network structure\n",
    "class BoWClassifier(nn.Module):  # inheriting from nn.Module!\n",
    "\n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        # needs to be done everytime in the nn.module derived class\n",
    "        super(BoWClassifier, self).__init__()\n",
    "\n",
    "        # Define the parameters that are needed for linear model ( Ax + b)\n",
    "        self.linear = nn.Linear(vocab_size, num_labels)\n",
    "\n",
    "        # NOTE! The non-linearity log softmax does not have parameters! So we don't need\n",
    "        # to worry about that here\n",
    "\n",
    "    def forward(self, bow_vec): # Defines the computation performed at every call.\n",
    "        # Pass the input through the linear layer,\n",
    "        # then pass that through log_softmax.\n",
    "\n",
    "        return F.log_softmax(self.linear(bow_vec), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Initialize the model\n",
    "bow_nn_model = BoWClassifier(NUM_LABELS, VOCAB_SIZE)\n",
    "bow_nn_model.to(device)\n",
    "\n",
    "# Loss Function\n",
    "loss_function = nn.NLLLoss()\n",
    "# Optimizer initlialization\n",
    "optimizer = optim.SGD(bow_nn_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train the model: 232.2170045375824\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(10):\n",
    "    for index, row in X_train.iterrows():\n",
    "        # Step 1. Remember that PyTorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        bow_nn_model.zero_grad()\n",
    "\n",
    "        # Step 2. Make BOW vector for input features and target label\n",
    "        bow_vec = make_bow_vector(review_dict, row['tokenized_text'])\n",
    "        target = make_target(Y_train['label'][index])\n",
    "\n",
    "        # Step 3. Run the forward pass.\n",
    "        probs = bow_nn_model(bow_vec)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss = loss_function(probs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "print(\"Time taken to train the model: \" + str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.67      0.67      2265\n",
      "           1       0.64      0.68      0.66      2288\n",
      "           2       0.69      0.65      0.67      2197\n",
      "\n",
      "    accuracy                           0.67      6750\n",
      "   macro avg       0.67      0.67      0.67      6750\n",
      "weighted avg       0.67      0.67      0.67      6750\n",
      "\n",
      "Time taken to predict: 2.853965997695923\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "bow_nn_predictions = []\n",
    "original_lables = []\n",
    "start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    for index, row in X_test.iterrows():\n",
    "        bow_vec = make_bow_vector(review_dict, row['tokenized_text'])\n",
    "        probs = bow_nn_model(bow_vec)\n",
    "        bow_nn_predictions.append(torch.argmax(probs, dim=1).cpu().numpy()[0])\n",
    "        original_lables.append(make_target(Y_test['label'][index]).cpu().numpy()[0])\n",
    "print(classification_report(original_lables,bow_nn_predictions))\n",
    "print(\"Time taken to predict: \" + str(time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
